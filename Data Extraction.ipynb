{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import fitz\n",
    "import nltk\n",
    "import glob\n",
    "import cv2\n",
    "import spacy\n",
    "import spacy.cli\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "import textseg as ts\n",
    "from spacy import displacy\n",
    "from PyPDF2 import PdfFileReader\n",
    "from pdf2image import convert_from_path\n",
    "\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "# spacy.cli.download(\"en_core_web_lg\")\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe' #tesseract.exe location in your computer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# SKILLS EXTRACTION\n",
    "# Add skills database from a file\n",
    "def add_skills_data(filePath):\n",
    "    skills = []\n",
    "\n",
    "    for data in open(filePath, 'r', encoding='UTF-8'):\n",
    "        skills.append(data.strip())\n",
    "\n",
    "    return skills\n",
    "\n",
    "# Get the text from a file\n",
    "def extract_text(filePath, remove_line=False):\n",
    "    with fitz.open(filePath) as doc:\n",
    "        text = \"\"\n",
    "        for page in doc:\n",
    "            text += page.get_text()\n",
    "\n",
    "        if remove_line:\n",
    "            text = text = re.sub('\\s', \" \", text)\n",
    "\n",
    "    return text\n",
    "\n",
    "# Extract the skills based on the skill database\n",
    "def extract_skills(input_text, skills_data):\n",
    "    stop_word = set(nltk.corpus.stopwords.words('english'))\n",
    "    word_tokens = nltk.tokenize.word_tokenize(input_text)\n",
    "\n",
    "    filtered_tokens = [w for w in word_tokens if w not in stop_word]\n",
    "    filtered_tokens = [w for w in word_tokens if w.isalpha()]\n",
    "    bigrams_trigrams = list(map(' '.join, nltk.everygrams(filtered_tokens, 2, 3)))\n",
    "\n",
    "    skills = set()\n",
    "\n",
    "    for token in filtered_tokens:\n",
    "        if token in skills_data:\n",
    "            skills.add(token)\n",
    "\n",
    "    for ngram in bigrams_trigrams:\n",
    "        if ngram in skills_data:\n",
    "            skills.add(ngram)\n",
    "\n",
    "    return skills\n",
    "\n",
    "# Extract skills from a single file\n",
    "def extract_single_skills(filePath, skills):\n",
    "    text = extract_text(filePath)\n",
    "\n",
    "    return  extract_skills(text, skills)\n",
    "\n",
    "# Extract skills from a folder full of pdf\n",
    "def extract_batch_skill(filePath, skills):\n",
    "    data = {\"File\": [], 'Skill': []}\n",
    "\n",
    "    for file in glob.glob('{}*.pdf'.format(filePath)):\n",
    "        text = extract_text(file, True)\n",
    "        data['File'].append(file)\n",
    "        data['Skill'].append(extract_skills(text, skills))\n",
    "\n",
    "    return data\n",
    "\n",
    "# DOCUMENT SEGMENTATION\n",
    "# Converting from pdf to image for segmentation\n",
    "def convert_pdf_to_image(filepath,img_path_to_save):\n",
    "    try:\n",
    "        fileName = filepath.split(\"/\")[-1].replace(\".pdf\",\"\")\n",
    "        pages = convert_from_path(filepath, 350)\n",
    "        i = 1\n",
    "        for page in pages:\n",
    "            image_name = img_path_to_save+fileName+\"Page_\" + str(i) + \".png\"\n",
    "            page.save(image_name, \"JPEG\")\n",
    "            i = i+1\n",
    "        return {\"status\":200,\"response\":\"PDF Converted to image sucessfully\",\"fileName\":fileName}\n",
    "    except Exception as e:\n",
    "        return {\"status\":400,\"response\":str(e)}\n",
    "\n",
    "# Extract text from a png\n",
    "def text_from_tesseract(output_img):\n",
    "    text = str(((pytesseract.image_to_string(output_img))))\n",
    "    return text\n",
    "\n",
    "# Segment and then extract the data from a resume\n",
    "def segment_extract_data(data,  path_to_write, singleFile=True):\n",
    "    documents = []\n",
    "\n",
    "    if singleFile:\n",
    "        documents.append(data)\n",
    "    else:\n",
    "        documents = data\n",
    "\n",
    "    final_name_list=[]\n",
    "    final_text_opencv=[]\n",
    "    final_text_tessaract=[]\n",
    "    for i in documents:\n",
    "        pdf = PdfFileReader(open(i,'rb'))\n",
    "        fname = i.split('/')[-1]\n",
    "        print(pdf.getNumPages())\n",
    "        images = convert_from_path(i)\n",
    "        resumes_img=[]\n",
    "        for j in range(len(images)):\n",
    "            # Save pages as images in the pdf\n",
    "            images[j].save(path_to_write+fname.split('.')[0]+'_'+ str(j) +'.jpg', 'JPEG')\n",
    "            resumes_img.append(path_to_write+fname.split('.')[0]+'_'+ str(j) +'.jpg')\n",
    "        name_list = fname.split('.')[0]+'_' +'.jpg'\n",
    "        text_opencv=[]\n",
    "        text_tessaract=[]\n",
    "        for i in resumes_img:\n",
    "            frame=cv2.imread(i)\n",
    "            os.remove(i)\n",
    "            img = i.split(\"/\")[2]\n",
    "\n",
    "            output_img,label,dilate, c_dict,df1, split_img=ts.get_text_seg(frame, img)\n",
    "            cv2.imwrite(path_to_write+img.split('.')[0]+\".png\",output_img)\n",
    "            for i in range(len(split_img)):\n",
    "                cv2.imwrite(path_to_write+img.split('.')[0]+str(i)+\".png\", split_img[i])\n",
    "\n",
    "            text_opencv.append(c_dict)\n",
    "            text_tessaract+=text_from_tesseract(output_img)\n",
    "            tesseract_str = ''.join(text_tessaract)\n",
    "\n",
    "        final_name_list.append(name_list)\n",
    "        final_text_opencv.append(text_opencv)\n",
    "        final_text_tessaract.append(tesseract_str)\n",
    "\n",
    "    return final_text_opencv, final_name_list, final_text_tessaract\n",
    "\n",
    "# EXPERIENCE EXTRACTION\n",
    "# Extract exp from a text\n",
    "def extract_exp(textList, nlp):\n",
    "    exp = []\n",
    "\n",
    "    for i in range(len(textList)):\n",
    "        for j in range(len(textList[i])):\n",
    "            for _, text in textList[i][j].items():\n",
    "                text = re.sub(r'[^\\w\\s]+', \"\", text)\n",
    "                text = re.sub(r'[\\s]{2,}', \" \", text)\n",
    "                text = re.sub(r'https\\w+', \"\", text)\n",
    "                doc = nlp(text)\n",
    "                if doc.cats['experience'] > 0.70:\n",
    "                    exp.append(text)\n",
    "\n",
    "    return exp\n",
    "\n",
    "# Do all the above with just 1 function\n",
    "def extract_data(filePath, skills, nlp, temp_path):\n",
    "    file_data = {'File': \"\", 'Skills':\"\", \"Exp\":\"\"}\n",
    "\n",
    "    textList, fileName, fullText = segment_extract_data(filePath, temp_path)\n",
    "    file_data['File'] = fileName[0]\n",
    "    file_data['Skills'] = extract_skills((fullText[0]), skills_data=skills)\n",
    "    file_data['Exp'] = extract_exp(textList, nlp)\n",
    "\n",
    "    return file_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Using CPU device\n",
      "Using CPU device\n"
     ]
    }
   ],
   "source": [
    "# Adding skills database\n",
    "skills = add_skills_data('list_of_skills.txt')\n",
    "skills[0] = '.NET' # First skills is not UTF-8 so we need to replace it\n",
    "\n",
    "# Segmentation need a temp folder for storing image that will be scanned for extraction the text\n",
    "temp_path = ('./segmentation/')\n",
    "\n",
    "# Load the machine learning model for exp classification\n",
    "nlp = spacy.load('model_best')\n",
    "\n",
    "# Get the filename, skills, exp\n",
    "data = extract_data('./sample/CV Dwi Wijaya 07 - Dwi WIjaya.pdf', skills, nlp, temp_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "{'File': 'CV Dwi Wijaya 07 - Dwi WIjaya_.jpg',\n 'Skills': {'Adobe',\n  'Adobe Photoshop',\n  'Basketball',\n  'CCNA',\n  'Capture',\n  'Cisco',\n  'Cisco Networking',\n  'Customer Experience',\n  'Customer Experience Management',\n  'Design',\n  'English',\n  'Excel',\n  'Fundamentals',\n  'Google Suite',\n  'Information Systems',\n  'Intermediate',\n  'KPI',\n  'Microsoft Excel',\n  'Microsoft Word',\n  'Office',\n  'Photoshop',\n  'Store',\n  'Suite',\n  'TOEIC',\n  'Word'},\n 'Exp': ['Store Maneyer Saleny City FABELIO Bekasi Febru ry 202 Oct ober 2021 Achievements and responsibilities Responsible for revenue gain and contribution target of KPI for respective showroom\\nManage responsibility for sales team on the respective showroom Directing all operational aspects of each store and driving sales whilst minimizing costs\\nAnalyses the strength of the products selling contribution revenue contribution contribution\\nper respective area etc Create business strategies to attract new customers expand store traffic and enhance\\nprofitability Motivate the sales team to meet sales objectives by training and mentoring staff Hire train and oversee new staff Undertake store administration duties such as managing store budgets and updating financial\\nrecords Monitor inventory levels and order new items Achievement achieve revenue 48 Billion in 1 year ',\n  'Sales Executive Bekasi FABELIO Bekasi January 2019 Janu 2020 Achievements and responsibilities\\ne Serve and answer customer questions about products product purchase process and\\nproduct availability\\ne Work together in teams to achieve showroom and personal goals\\ne Collect data from customers who come to the showroom\\ne Achievement achieve personal revenue 2 Billion in 1 year ',\n  'Customer Experience Management Intern Fabelio Bekasi Achievements and responsibilities Understand your customers Create a customer journey map Develop an emotional connection to your band\\nCapture customer feedback to track satisfaction Certificate ']}"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Outputing the data\n",
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}